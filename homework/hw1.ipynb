{"cells": [{"outputs": [], "cell_type": "code", "execution_count": null, "metadata": {}, "source": [""]}, {"cell_type": "markdown", "metadata": {}, "source": ["# MCIS6273 Data Mining (Prof. Maull) / Fall 2017 / HW1\n", "\n", "**This assignment is worth up to 20 POINTS to your grade total if you complete it on time.**\n", "\n", "| Points <br/>Possible | Due Date | Time Commitment <br/>(estimated) |\n", "|:---------------:|:--------:|:---------------:|\n", "| 20 | Saturday, Sep 30 @ Midnight | _up to_ 10 hours |\n", "\n", "\n", "* **GRADING:** Grading will be aligned with the completeness of the objectives.\n", "\n", "* **INDEPENDENT WORK:** Copying, cheating, plagiarism  and academic dishonesty _are not tolerated_ by Univerisity or course policy.  Please see the syllabus for the full departmental and University statement on the academic code of honor.\n", "\n", "## OBJECTIVES\n", "* Work with core Pandas and Scikit-Learn concepts in data, data types, representation of data and plotting data\n", "\n", "* Explore concepts in statistical inference over real data within Scikit-Learn\n", "\n", "* Work with data to understand distance metrics in Scikit-Learn and the impact various metrics have on the outcomes\n", "\n", "## WHAT TO TURN IN\n", "You are being encouraged to turn the assignment in using the provided\n", "Jupyter Notebook.  To do so, clone\n", "[the course repository](https://github.com/kmsaumcis/mcis6273_f17_datamining) and modify\n", "the `hw1.ipynb` file in the `homework/hw1` directory.  If you do not know\n", "how to do this, please ask, or visit one of the many tutorials out there\n", "on the basics of using Github and cloning repositories.\n", "\n", "Turn in a copy of a `.ipynb` file, a PDF or Word Document to Blackboard\n", "with the answers to the questions labeled with the &#167; sign.\n", "\n", "## ASSIGNMENT TASKS\n", "### (20%) Work with core Pandas and Scikit-Learn concepts in data, data types, representation of data and plotting data \n", "\n", "A great deal of time doing data mining involves understanding the data in a dataset and preprocessing it in preparation for working with it in a real analysis of some sort.  We will develop an understanding of:\n", "\n", "  * how to empirically perform and understand the descriptive statistics of a dataset,\n", "  * understand how to reason about data features,\n", "  * understand how to use distance metrics,\n", "  * understand binarizaration contexts abd techniques, and\n", "  * understand how to randomly sample datasets to understand the distribution of data.\n", "\n", "We'll be working a new  much smaller dataset for this task.  Please check the repository for the [`bank.csv` data set](https://github.com/kmsaumcis/mcis6273_f17_datamining/blob/master/homework/hw1/bank-data.csv).  There are fewer than 1000 rows to work with in this data.  You will need to use [Pandas](http://pandas.pydata.org/) and [Scikit-Learn](http://scikit-learn.org/stable/index.html) for all the questions here, and it is recommended you take a look at the optional cheat sheets [for lecture 2 in the syllabus](https://kmsaumcis.gitbub.io/mcis6273_f17_datamining/syllabus):\n", "\n", "  * [Pandas Cookbook Github Repo](https://github.com/jvns/pandas-cookbook)\n", "  * [Pandas Cheatsheet @ DataCamp.com](https://s3.amazonaws.com/assets.datacamp.com/blog_assets/PandasPythonForDataScience.pdf)\n", "\n", "&#167;  In the readings and lecture, we talked about distributions of data.  Please produce the frequency distribution (histogram) for the following:  (1) rural income, (2) car ownership.  You will most certainly need to use the [`pandas.Series.plot.hist()`](http://pandas.pydata.org/pandas-docs/stable/visualization.html#visualization-hist) method.\n", "\n", "\n", "&#167;  Produce the scatter plot for income vs age -- it doesn't matter which\n", "is on the $x$ and $y$ axis.  You will benefit from the [`DataFrame.plot.scatter()`](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.plot.scatter.html#pandas.DataFrame.plot.scatter) method.\n", "\n", "\n", "\n", "### (40%) Explore concepts in statistical inference over real data within Scikit-Learn \n", "\n", "**For questions 1-3**: Just answer the question over the entire data\n", "as requested.\n", "\n", "**For questions 4 and 5**: Consider this scenario ...\n", "\n", "> The bank is looking for candidates who might be good for sending\n", "mortgage loan information to -- that is they are looking for people\n", "who are **not homeowners** (i.e. don't own a home), but who have\n", "the income and other characteristics of potentially good\n", "borrowers.\n", "\n", "> Your task is to look at all the data for people who have no mortgage\n", "and build the case for the profile of the borrower (from this dataset)\n", "that they should start calling, sending mail and advertising to.\n", "\n", "> Imagine you are a real-world analyst and will need to do the following:\n", "\n", "* build the dataset that contains non-homeowners (i.e. no mortgage)\n", "* report on the characteristics of non-homeowners based on what is being asked\n", "\n", "&#167;  What is the median age of a `UNMARRIED`, `FEMALE`, `HOME OWNER` in the `SUBURBAN` region?\n", "\n", "\n", "&#167;  Given this bank datset what is the joint probability $\\Pr( \\mathrm{sex} = MALE \\wedge \\mathrm{income} \\ge 50,000 )$?  How does this compare with $\\Pr( \\mathrm{sex} = FEMALE \\wedge \\mathrm{income} \\ge 50,000 )$?\n", "\n", "\n", "&#167;  What is  conditional probability $\\Pr( car = \\mathrm{TRUE} \\big| sex = \\mathrm{MALE} \\wedge income \\ge \\mathrm{50,000} )$?\n", "\n", "\n", "&#167;  If the lending requirements were a savings account and income greater\n", "than $45,000, what about this data might make it difficult to justify\n", "any campaign at all?  (**HINT:** most mortgages are 30-years in duration) Provide **concrete evidence** for your claims; you may do this in a variety of ways _including describing the statistic that leads you to your claim_.\n", "\n", "\n", "&#167;  If the savings account requirement was ignored and the income\n", "lowered to a minimum of $30,000, to whom (`MALE` or `FEMALE`) and in\n", "which region (`RURAL`, `TOWN`, `INNER_CITY`, `SUBURBAN`) would\n", "the bank likely have the best success?\n", "\n", "\n", "\n", "### (40%) Work with data to understand distance metrics in Scikit-Learn and the impact various metrics have on the outcomes \n", "\n", "A common thing to understand in a dataset is to determine some\n", "number of _nearest neighbors_ to a data point.  We will see this come\n", "back when we get to clustering.  For now, let's explore the\n", "[NearestNeighbor](http://scikit-learn.org/stable/modules/generated/sklearn.neighbors.NearestNeighbors.html#sklearn.neighbors.NearestNeighbors)\n", "implementation in Scikit-Learn.\n", "\n", "You will most certainly need to convert the categorical non-numeric data\n", "to binary features, and you may be served well by reading about\n", "[preprocessing data in Scikit-Learn](http://scikit-learn.org/stable/modules/preprocessing.html#preprocessing) and also taking\n", "a closer look at [`sklearn.preprocessing.LabelBinarizer`](http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelBinarizer.html#sklearn.preprocessing.LabelBinarizer) and [`sklearn.preprocessing.OneHotEncoder`](http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html#sklearn.preprocessing.OneHotEncoder).  You might also find\n", "[this resource](https://courses.edx.org/c4x/BerkeleyX/CS190.1x/asset/CS190.1x_week4b.pdf)\n", "of value if you read only the first few slides on binarization.\n", "\n", "&#167;  What are the 5 nearest neighbors (the indices) to index #7, #21, #40\n", "and #94?  Your output will be a list of the tuples\n", "of the 5 closest indices and their values (e.g. `[(5, 4.56356), (19, 8.83452), (233, 12.23486), ...]`).  Use the _minkowski\n", "(default) distance_ first.\n", "\n", "\n", "&#167;  Use the _cosine similarity metric_ and _euclidean distance metric_\n", "(e.g. invoke `NearestNeighbor(..., metric='cosine')` and `NearestNeighbor(..., metric='euclidean')`).\n", "Produce the same lists for the same indices as in #1.  What are\n", "the differences in the nearest neighbor lists?  Which seem to be\n", "the most similar? Provide your thoughts on why there are differences?\n", "\n", "\n"]}], "nbformat": 4, "metadata": {"language_info": {"name": "python", "nbconvert_exporter": "python", "codemirror_mode": {"name": "ipython", "version": 3.0}, "pygments_lexer": "ipython3", "file_extension": ".py", "mimetype": "text/x-python", "version": "3.6.1"}, "toc": {"toc_cell": false, "threshold": "1", "widenNotebook": false, "toc_section_display": "block", "sideBar": true, "nav_menu": {"width": "252px", "height": "12px"}, "navigate_menu": true, "moveMenuLeft": true, "number_sections": false, "toc_window_display": true, "colors": {"wrapper_background": "#FFFFFF", "navigate_text": "#333333", "sidebar_border": "#EEEEEE", "selected_highlight": "#FFD700", "navigate_num": "#000000", "running_highlight": "#FF0000", "hover_highlight": "#DAA520"}}, "kernelspec": {"name": "python3", "language": "python", "display_name": "Python [default]"}, "anaconda-cloud": {}}, "nbformat_minor": 0}